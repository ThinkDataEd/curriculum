[
  {
    "title": "Abstract: Exploring Nonlinear Prediction Models in Unit 4 Lab 4E",
    "body": "This abstract provides an overview of Unit 4 Lab 4E, 'Some models have curves,' which focuses on developing and comparing nonlinear prediction models with traditional linear models. The lab guides users through the process of loading and splitting the `movie` dataset into `training` and `test` sets, a crucial step for model evaluation. Initially, a linear model is trained and its performance is assessed using Mean Squared Error (MSE) on the `test` data. The core of the lab involves introducing and implementing quadratic and cubic curve fitting using R's `poly()` function to address scenarios where the relationship between data is nonlinear. Participants will train these more flexible models, visualize their fits alongside the linear model, and quantitatively compare their performance using `test` MSE. The lab culminates in identifying the most effective model for predicting `audience_rating` based on `critics_rating`, demonstrating the advantages of flexible models for curved data. The instructions emphasize interactive learning, with blue questions to be completed on the computer and red questions answered in a journal."
  },
  {
    "title": "Introduction to Nonlinear Models and Unit 4 Lab 4E Objectives",
    "body": "Unit 4 Lab 4E, titled 'Some models have curves,' introduces the concept of nonlinear prediction models, contrasting them with the linear 'line of best fit' models previously explored. The primary objective of this lab is to teach participants how to fit 'best fitting curves' to data when the underlying relationship is nonlinear, rather than being accurately represented by a straight line. This lab addresses the limitations of linear models when faced with curved data. Participants will learn to identify situations where a linear model provides poor predictions and explore more flexible alternatives such as quadratic and cubic curves. The lab's instructions guide users through practical R coding exercises, with questions in blue to be executed on the computer and questions in red to be reflected upon and answered in a journal, ensuring a comprehensive learning experience."
  },
  {
    "title": "Data Preparation: Splitting the `movie` Dataset in Unit 4 Lab 4E",
    "body": "A foundational step in Unit 4 Lab 4E, 'Some models have curves,' involves the meticulous preparation of the `movie` dataset. Before any models are trained or evaluated, the data must be appropriately split to ensure robust model assessment. Participants are instructed to load the `movie` data and then divide it into two distinct sets: a `training` set, which comprises 75% of the total data, and a `test` set, containing the remaining 25%. This division is critical for preventing overfitting, where a model learns the training data too well but performs poorly on unseen data. To ensure reproducibility of the data split, the `set.seed` function must be utilized. The `training` set will be used for developing and optimizing the prediction models, while the `test` set will serve as an independent benchmark to evaluate their true predictive performance, particularly in the later stages when comparing linear and nonlinear models. This process ensures that model comparisons are fair and reliable."
  },
  {
    "title": "Establishing a Baseline: Training and Evaluating a Linear Model in Unit 4 Lab 4E",
    "body": "In Unit 4 Lab 4E, 'Some models have curves,' before diving into nonlinear models, a linear model serves as a crucial reference point. Participants are tasked with training a linear prediction model using the `training` data. This model, named `movie_linear`, aims to predict `audience_rating` based on `critics_rating` using a simple linear relationship, represented by the equation `y = a + bx`. After training, the performance of this linear model is assessed. An important step involves visualizing its fit by creating a scatterplot of `audience_rating` versus `critics_rating` using the `test` data, and then overlaying the *line of best fit* using the `add_curve` function. This visualization helps in qualitatively understanding how well the line fits the data, especially at extreme values of `critics_rating`, where linear models often show their limitations. Subsequently, to quantitatively measure its performance, the Mean Squared Error (MSE) of `movie_linear` is computed using the `test` data, a metric previously covered in Unit 4 Lab C. This initial evaluation provides a benchmark against which the more flexible nonlinear models will be compared."
  },
  {
    "title": "Visualizing and Quantifying Linear Model Performance in Unit 4 Lab 4E",
    "body": "In Unit 4 Lab 4E, 'Some models have curves,' the initial assessment of the linear model, `movie_linear`, involves both qualitative and quantitative methods. After training `movie_linear` on the `training` data to predict `audience_rating` from `critics_rating`, its fit is visualized using a scatterplot. This plot is generated using `xyplot(audience_rating ~ critics_rating, data = test)` and then the *line of best fit* is added with `add_curve(movie_linear)`. Participants are prompted to critically observe how well this line fits the data, specifically noting any `critics_rating` values that would lead to 'obviously poor predictions,' often observed at the lower and higher ends of the independent variable when the true relationship is nonlinear. This visual inspection highlights the inherent limitations of linear models when applied to curved data. To complement this visual analysis, the Mean Squared Error (MSE) of the linear model is calculated using the unseen `test` data. This MSE value, a key indicator of prediction accuracy (referencing Unit 4 Lab C), is recorded for direct comparison with the MSEs of the more flexible quadratic and cubic models introduced later in Unit 4 Lab 4E, providing an objective measure of performance."
  },
  {
    "title": "Introducing Flexibility: Beyond Linear Models with Quadratic and Cubic Curves in Unit 4 Lab 4E",
    "body": "Unit 4 Lab 4E, 'Some models have curves,' emphasizes that a simple linear model is often inadequate for capturing complex, nonlinear relationships within data. When data exhibits a curved pattern, it necessitates a more flexible modeling approach than the standard `y = a + bx` linear equation. This lab introduces polynomial regression as a solution, specifically focusing on quadratic and cubic curves. A quadratic curve, represented by the equation `y = a + bx + cx^2`, adds a squared term of the independent variable, allowing the model to capture a single bend in the data. Further increasing flexibility, a cubic curve, with the equation `y = a + bx + cx^3`, incorporates a cubed term, enabling the model to represent two bends. The core principle highlighted is that the greater the number of coefficients in a model—that is, the higher the degree of the polynomial—the more 'bend-y' or flexible its predictions can become. This increased flexibility allows these models to better approximate the true, nonlinear relationship observed in datasets like the `movie` data, moving beyond the constraints of a straight line."
  },
  {
    "title": "Implementing Quadratic Prediction Models Using R's `poly()` Function in Unit 4 Lab 4E",
    "body": "To effectively model nonlinear relationships in Unit 4 Lab 4E, 'Some models have curves,' R provides the `poly()` function, which is crucial for fitting polynomial curves. Participants learn to train a quadratic model, named `movie_quad`, that predicts `audience_rating` based on `critics_rating`. This is achieved using the `lm()` function in conjunction with `poly()`, specifically `movie_quad <- lm(audience_rating ~ poly(critics_rating, 2), data = training)`. The `poly()` function transforms the independent variable, `critics_rating`, into orthogonal polynomial terms, allowing `lm()` to fit a quadratic curve. The key parameter within `poly()`, the number `2` in `poly(critics_rating, 2)`, specifies the *degree* of the polynomial. In this context, `2` indicates that a quadratic curve, involving terms up to `critics_rating` squared, should be fitted. This method allows the model to capture a single curvature in the data, offering greater flexibility than the linear model. This technique is central to developing more accurate prediction models for data exhibiting nonlinear trends, as demonstrated in Unit 4 Lab 4E."
  },
  {
    "title": "Visual and Quantitative Comparison of Linear and Quadratic Models in Unit 4 Lab 4E",
    "body": "A crucial aspect of Unit 4 Lab 4E, 'Some models have curves,' is the direct comparison between the initial linear model and the newly introduced quadratic model. Participants are instructed to create a scatterplot using the `test` data for `audience_rating` against `critics_rating`, similar to the earlier visualization. However, this time, both the *line of best fit* from `movie_linear` and the *best fitting quadratic curve* from `movie_quad` are added to the same plot using `add_curve()` with distinct colors (e.g., `col = \"blue\"` for linear and `col = \"red\"` for quadratic). This dual visualization allows for a clear qualitative comparison of how each model approximates the data's underlying trend. Following this visual inspection, participants are prompted to hypothesize which model will exhibit a lower `test` Mean Squared Error (MSE), indicating superior predictive performance. The lab then requires the computation of the MSE for the quadratic model using the `test` data, which is then compared directly to the MSE of the linear model. This quantitative comparison, leveraging the `test` MSE, provides concrete evidence to explain why one model—typically the quadratic for curved data—fits better than the other, thereby validating the benefits of increased model flexibility."
  },
  {
    "title": "Expanding to Cubic Models and Comprehensive Performance Comparison in Unit 4 Lab 4E",
    "body": "In the 'On your own' section of Unit 4 Lab 4E, 'Some models have curves,' participants further explore model flexibility by training a cubic prediction model. This model, named `movie_cubic`, predicts `audience_rating` using `critics_rating` with a polynomial of degree `3`. Similar to the quadratic model, this involves using the `poly()` function within `lm()`, but with `3` as the degree parameter, allowing for even more complex curve fitting. After training, a comprehensive visualization is performed: a scatterplot of the `test` data is created, and then the *line of best fit* from `movie_linear`, the *best fitting quadratic curve* from `movie_quad`, and the *best fitting cubic curve* from `movie_cubic` are all added to the same plot. This allows for a direct visual assessment of all three models' capabilities in capturing the data's nuances. Based on this visual evidence, participants form an initial hypothesis about which model performs best on the `test` data. The ultimate verification, however, comes from quantitatively comparing the `test` Mean Squared Errors (MSEs) for all three models (linear, quadratic, and cubic). This final step confirms which model truly offers the most accurate predictions for unseen data, underscoring the importance of selecting an appropriate model complexity for the underlying data structure, as emphasized throughout Unit 4 Lab 4E."
  },
  {
    "title": "Understanding the `poly()` Function and Model Flexibility for Curve Fitting in Unit 4 Lab 4E",
    "body": "A central concept in Unit 4 Lab 4E, 'Some models have curves,' is the ability to fit flexible curves to data using polynomial regression, specifically through R's `poly()` function. When fitting models like `movie_quad` or `movie_cubic`, the `poly()` function is employed within the `lm()` call (e.g., `lm(audience_rating ~ poly(critics_rating, 2), data = training)`). The number argument in `poly()`, such as `2` for a quadratic model or `3` for a cubic model, directly specifies the *degree* of the polynomial. This degree determines the maximum power of the independent variable included in the model, thus controlling the model's flexibility. A degree of `2` allows for terms up to `x^2` (quadratic), while `3` allows terms up to `x^3` (cubic). The more flexible a model is (i.e., higher polynomial degree and more coefficients), the better it can adapt to and capture complex, curved relationships in the data, potentially leading to more accurate predictions than a simple linear model. However, excessive flexibility can also lead to overfitting, a balance that is explored through the comparison of test MSEs in Unit 4 Lab 4E, highlighting the importance of choosing the right level of complexity."
  },
  {
    "title": "Mean Squared Error (MSE): Quantifying Model Performance in Unit 4 Lab 4E",
    "body": "Throughout Unit 4 Lab 4E, 'Some models have curves,' the Mean Squared Error (MSE) serves as the primary quantitative metric for evaluating and comparing the predictive performance of different models. As established in Unit 4 Lab C, MSE measures the average squared difference between the predicted values and the actual observed values. A lower MSE indicates a model that makes more accurate predictions. In Unit 4 Lab 4E, MSE is first calculated for the baseline linear model, `movie_linear`, using the unseen `test` data. Subsequently, the MSE for the quadratic model, `movie_quad`, and later for the cubic model, `movie_cubic`, are also computed using the same `test` data. The consistent use of the `test` set for MSE calculation is crucial to ensure an unbiased evaluation of how well each model generalizes to new data, rather than simply how well it fits the data it was trained on. By comparing the MSE values across the linear, quadratic, and cubic models, participants can objectively determine which model offers the best predictive capability for the `movie` dataset's `audience_rating` based on `critics_rating`, thereby validating or refuting visual assessments of model fit. This quantitative approach is fundamental to making informed decisions about model selection."
  }
]