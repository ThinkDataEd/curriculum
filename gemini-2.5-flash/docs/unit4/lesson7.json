[
  {
    "title": "Abstract: Unit 4 Lesson 7 - Statistical Predictions and Error Rules",
    "body": "This lesson, Unit 4 Lesson 7, focuses on applying statistical rules to determine the best method for predicting heights for students at a high school. Students will learn about essential data science concepts such as training data and test data. The core objective is to understand and apply two widely used error metrics: Mean Squared Error (MSE) and Mean Absolute Error (MAE). Through practical exercises and R demonstrations, students will discover that the choice of the 'best' prediction statistic (mean or median) depends directly on the chosen error rule. Specifically, the mean is the optimal predictor when using the MSE rule, while the median is optimal when using the MAE rule. The lesson utilizes handouts like *Heights of Students at a Large High School* (LMR_U4_L6), *A Tale of Two Rules* (LMR_U4_L7_A), and *Prediction Games* (LMR_U4_L7_B) to facilitate hands-on learning and reinforces key vocabulary such as residual."
  },
  {
    "title": "Unit 4 Lesson 7 Overview: Predicting Heights with Statistical Rules",
    "body": "Unit 4 Lesson 7, titled 'Statistical Predictions Applying the Rule,' aims to teach students how to apply the statistical rules used to determine the best method for predicting heights. The lesson requires several materials, including each teamâ€™s rule for determining a winner from the previous lesson, the *Heights of Students at a Large High School* handout (LMR_U4_L6), the *A Tale of Two Rules* handout (LMR_U4_L7_A), and the *Prediction Games* handout (LMR_U4_L7_B). Students begin by recalling their self-created rules from the previous lesson. They then shift roles, being given a statistical rule and tasked with finding the best prediction to win a contest. This involves referring back to the *Heights of Students at a Large High School* handout (LMR_U4_L6) which provides height data. Key vocabulary for this lesson includes 'training data,' 'test data,' 'mean squared error,' 'mean absolute error,' and 'residual,' all crucial for understanding how predictions are evaluated."
  },
  {
    "title": "Training and Test Data in Unit 4 Lesson 7 Predictions",
    "body": "In Unit 4 Lesson 7, the process of making statistical predictions for student heights begins by distinguishing between different types of datasets. Students utilize data on 40 selected students, referred to as the **training data**, to develop their predictive models. This 'training data' is a random subset, typically comprising 75-85% of the original dataset, used to train a model. Once a model is trained, its predictions are evaluated using **test data**, which consists of another random subset, usually 15-25% of the original data. In the context of predicting heights, initial teams used different statistics from the training data for their predictions: Team A used the mean, Team B used the median, and Team C used the third quartile. The lesson explores how these different prediction methods fare when evaluated against new observations using established statistical error rules. This distinction between training and test data is a fundamental practice in statistics and data science, ensuring that models are robust and perform well on unseen data. The *Heights of Students at a Large High School* handout (LMR_U4_L6) provides the foundational height data for these exercises."
  },
  {
    "title": "Introduction to Mean Squared Error (MSE) in Statistical Prediction",
    "body": "Unit 4 Lesson 7 introduces students to the Mean Squared Error (MSE) as a primary method statisticians and data scientists use to evaluate predictions. The MSE rule is used to determine the winner among different prediction methods. An 'error' or 'residual' is defined as the difference between a prediction and the actual outcome. The Mean Squared Error (MSE) is calculated by finding the average of the squared differences between predictions and actual values. Other names for MSE include Mean Squared Deviation and Mean Squared Residual. The formula for MSE is given as <img src=\"https://latex.codecogs.com/gif.latex?MSE=\\frac{\\sum_{i=1}^{n}(x_i-\\hat{x})^2}{n}\" title=\"\\frac{\\sum_{i=1}^{n}(x_i-\\hat{x})^2}{n}\" />, where <img src=\"https://latex.codecogs.com/gif.latex?\\hat{x}\" title=\"\\hat{x}\" /> represents the predicted value and <img src=\"https://latex.codecogs.com/gif.latex?x_i\" title=\"x_i\" /> represents the actual values. The objective is to identify the prediction method that yields the lowest mean squared error, as this indicates the most accurate predictions according to this rule. A crucial 'Essential Concept' highlighted in this lesson states that if the Mean Squared Errors rule is applied, the mean of the current data is the best prediction of future values."
  },
  {
    "title": "Practical Application of Mean Squared Error (MSE) Using R",
    "body": "In Unit 4 Lesson 7, students learn to calculate the Mean Squared Error (MSE) using R programming. A practical example demonstrates this by creating a vector of heights (`heightA`) for Dataset A and converting it into a dataframe. The residuals are then calculated by subtracting a predicted value (e.g., 65 inches, representing the first quartile from the training data) from each actual height. These residuals are then squared (`sq_res=residual^2`). Finally, the `mean` function is used to sum the squared residuals and divide by the number of observations (10 for Dataset A) to obtain the MSE. For instance, this process might yield an MSE of 22.05. It's important to note that MSE values are always in square units. To interpret this error in the original units (e.g., inches for height), the square root of the MSE is taken. For example, an MSE of 22.05 implies that predictions are typically off by approximately <img src=\"https://latex.codecogs.com/gif.latex?\\inline&space;\\sqrt{22.05}=4.6957\" title=\"\\sqrt{22.05}=4.6957\" /> inches. This R-based calculation is vital for evaluating team predictions from the *A Tale of Two Rules* handout (LMR_U4_L7_A), where teams determine the winner based on the lowest MSE. This reinforces the 'Essential Concept' that the mean is the best predictor when using the MSE rule."
  },
  {
    "title": "Mean as the Optimal Predictor under Mean Squared Error (MSE) Rule",
    "body": "After calculating the Mean Squared Error (MSE) for various team predictions using the *A Tale of Two Rules* handout (LMR_U4_L7_A) in Unit 4 Lesson 7, students observe a consistent pattern. When MSE is the chosen metric, the statistic that typically yields the lowest error and thus 'wins' the prediction contest is the mean. This outcome reinforces a key 'Essential Concept' of the lesson: if the Mean Squared Errors rule is applied, then the mean of the current data is the best prediction of future values. Data scientists and mathematicians can prove that the mean will almost always be the best single guess when using MSE, with only rare exceptions. This principle guides optimal prediction strategies when the goal is to minimize the sum of squared differences between predictions and actual outcomes. The lesson emphasizes that understanding the error rule is critical because it dictates the choice of the best prediction statistic. This foundational knowledge about MSE and the mean's optimality is crucial for making informed statistical predictions."
  },
  {
    "title": "Exploring Mean Absolute Error (MAE) as an Alternative Prediction Metric",
    "body": "Unit 4 Lesson 7 also introduces the Mean Absolute Error (MAE) as another widely accepted method used by data scientists and statisticians for evaluating predictions. Unlike MSE, which squares the residuals, MAE calculates the average of the absolute differences between predictions and actual outcomes. The MAE formula is given as <img src=\"https://latex.codecogs.com/gif.latex?MAE=\\frac{&space;&space;\\sum_{i=1}^{n}&space;|x_i-\\hat{x}|}{n}\" title=\"MAE=\\frac{&space;&space;\\sum_{i=1}^{n}&space;|x_i-\\hat{x}|}{n}\" >, where <img src=\"https://latex.codecogs.com/svg.image?\\hat{x}\" title=\"\\hat{x}\" /> represents the predicted value. The use of absolute values means that MAE provides a direct, interpretable measure of the average magnitude of errors, in the original units of the data. This rule offers a different perspective on prediction accuracy compared to MSE. The lesson highlights an 'Essential Concept': if the Mean Absolute Errors rule is applied, then the median of the current data is the best prediction of future values. This means the optimal prediction strategy changes based on whether MSE or MAE is the chosen metric for evaluation."
  },
  {
    "title": "Practical Application of Mean Absolute Error (MAE) Using R",
    "body": "Continuing from the Mean Squared Error, Unit 4 Lesson 7 guides students through calculating the Mean Absolute Error (MAE) using R. The process again starts with a dataset, such as `datasetA` from *Heights of Students at a Large High School* (LMR_U4_L6). Instead of squaring the residuals, the R script for MAE involves calculating the absolute value of the residuals (`residual=abs(heightA-65)`), where `65` inches is an example prediction (e.g., first quartile). Finally, the `mean` function is used to sum these absolute residuals and divide by the number of observations to find the MAE. For instance, this calculation might yield a Mean Absolute Error of 4.32. This value directly represents the average magnitude of the prediction errors in the original units (e.g., inches). After performing these calculations, students will use the *A Tale of Two Rules* handout (LMR_U4_L7_A) to determine which team's prediction statistic (mean, median, or third quartile) results in the lowest MAE. This exercise demonstrates how different error metrics can lead to different 'winners' and reinforces the 'Essential Concept' that the median becomes the best predictor when using the MAE rule."
  },
  {
    "title": "Median as the Optimal Predictor under Mean Absolute Error (MAE) Rule",
    "body": "In Unit 4 Lesson 7, after applying the Mean Absolute Error (MAE) rule to evaluate the teams' predictions for student heights, a distinct outcome emerges compared to using MSE. When MAE is the chosen criterion for determining the 'winner,' the median statistic (as used by Team B) typically proves to be the most effective predictor, yielding the lowest MAE. This finding is central to one of the lesson's 'Essential Concepts': if the Mean Absolute Errors rule is applied, then the median of the current data is the best prediction of future values. This illustrates a critical principle in statistical prediction: the 'best' method for prediction is not absolute but is contingent upon the chosen error metric. If the goal is to minimize the average absolute difference between predictions and actual values, then the median is the optimal single guess. This understanding is further solidified by observing how the winner shifts from the mean (with MSE) to the median (with MAE), underscoring the importance of selecting the appropriate error rule for a given context."
  },
  {
    "title": "Connecting Error Rules: Mean for MSE, Median for MAE, and Practice Opportunities",
    "body": "Unit 4 Lesson 7 culminates in a crucial understanding: the optimal prediction statistic depends entirely on the chosen error rule. The 'Essential Concepts' clearly state that if the Mean Squared Error (MSE) rule is applied, the mean of the current data is the best prediction of future values. Conversely, if the Mean Absolute Error (MAE) rule is applied, the median of the current data is the best prediction of future values. This core takeaway, reinforced by practical calculations with R and analysis of team predictions, highlights that the 'way you play the game depends on the rules of the game.' For further practice, students have the option to use the *Prediction Games* handout (LMR_U4_L7_B). This handout allows them to reinforce their understanding of calculating both MSE and MAE for predictions based on the mean and median, and it includes a five-number summary for additional context. The lesson concludes with Class Scribes summarizing the three most important topics, ensuring that students internalize these fundamental principles of statistical prediction and error evaluation."
  }
]