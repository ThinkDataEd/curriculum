##***<u>Lesson 4: Evaluate and Implement the Campaign</u>***

###**Objective:**
Students will complete the design of their community focused Participatory Sensing campaign and implement a mock campaign to evaluate the feasibility of the campaign.

###**Materials:**
1. *Team Campaign Creation* handout ([LMR_U4_L2](../IDS_Curriculum_v_5.0/2_IDS_LMRs_v_6.0/IDS_LMR_Unit4_v_7/LMR_U4_L2.pdf)) from previous lesson

###**Essential Concepts:**

!!! note "Essential Concepts: "
    Statistical investigative questions guide a Participatory Sensing campaign so that we can learn about a
    community or ourselves. These campaigns should be evaluated before implementing to make sure they are
    reasonable and ethically sound.

###**Lesson:**
1. Student teams will continue designing their Participatory Sensing campaign. Allow them some time to review their possible research questions with their team and to decide on a team research question before moving on to Round 3.

2. <u>Round 3:</u> Allow student teams a reasonable amount of time to engage in a brainstorm, in which
they will discuss what kind of data needs to be collected in order to answer this research question
and when is the best time to trigger the data collection/ completion of the survey. Before they
begin, ask students to keep the following question in mind: Which of these data will give us
information that addresses our research question?

3. Once teams have decided on their types of data and trigger, they will create survey questions/prompts to collect this type of data with this trigger.

4. <u>Round 4:</u> Now that the teams have decided on a trigger and the type of data needed, they will
discuss and create survey questions/ prompts to ask when the trigger is set. The questions should
consider all of the possible data they might collect at this trigger event.

5. Once teams have created their survey questions/ prompts, they will evaluate each survey
question. For each question they should consider:

    100. What type of survey question/ prompt will this be (e.g. number, text, photo,
    time, single choice)?

    100. How does this question/ prompt help address the research question?

    100. Does the question/ prompt need to be reworded? (Is it clear what is being asked for? Do
    they know how to answer it?) One way to do this is to pair teams and take turns asking
    each other prompts. The team that is being asked may explain what information they
    think the question is asking for.

6. If survey questions need to be rewritten, students will decide as a team on the changes.

7. Once finalized, they will record the survey question/ prompt that goes along with each data
variable on their *Team Campaign Creation* handout ([LMR_U4_L2](../IDS_Curriculum_v_5.0/2_IDS_LMRs_v_6.0/IDS_LMR_Unit4_v_7/LMR_U4_L2.pdf)), being cognizant of question bias.

    <div align="right"><iframe src="https://docs.google.com/viewerng/viewer?url=https://curriculum.thinkdataed.org/IDS_Curriculum_v_5.0/2_IDS_LMRs_v_6.0/IDS_LMR_Unit4_v_7/LMR_U4_L2.pdf&embedded=true" style=" width:420px;height:400px;" frameborder="0"></iframe><br>[LMR_U4_L2](../IDS_Curriculum_v_5.0/2_IDS_LMRs_v_6.0/IDS_LMR_Unit4_v_7/LMR_U4_L2.pdf)</div>

8. <u>Round 5:</u> In teams, students will now generate three statistical investigative questions that they might answer
with the data they will collect and to guide their campaign. They need to make sure that their
statistical investigative questions are interesting and relevant to their chosen topic. Remind students that they will also have data about the date,
time, and place of data collection.

9. Confirm that the questions are statistical and that they can be answered with the data the
students propose to collect by circulating around the room to check on each team. Each team will
decide on no more than 3 statistical investigative questions to guide their campaign.

10. Now that they have all the pieces of the campaign, teams will evaluate whether their campaign is
reasonable and ethically sound. Each team will hold a discussion on the following questions:

    100. Are answers to your survey questions likely to *vary* when the trigger occurs? (If not, you'll
    get bored entering the same data again and again)

    100. Can the team carry out the campaign?

    100. Do triggers occur so rarely that you'll have very little data? Do they occur so often that
    you'll get frustrated entering too much data?

    100. Ethics: Would sharing these data with strangers or friends be embarrassing or undermine
    someone's privacy?

    100. Can you change your trigger or survey questions to improve your evaluation?

    100. Will you be able to gather enough relevant data from your survey questions to be able to
    answer your statistical investigative questions?

11. During their discussion about whether their campaign is reasonable and ethically sound, if teams discover that they need to make changes, they can make adjustments at this time.

12. Students have collaboratively created their Team Participatory Sensing campaign.

###**Class Scribes:**
One team of students will give a brief talk to discuss what they think the 3 most important topics of the
day were.

###<p style="background: black; color: white; text-align: center;">**Homework**</p>
Students will collect data by mock implementing their Team Participatory Sensing campaign.